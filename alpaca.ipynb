{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "lCBInWLuKzd5",
        "outputId": "bf93bb7b-ee9d-4f12-b9ac-c6221ca6ff19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ•’  Scheduler started â€” Ctrl+C to stop\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-24016d9cc931>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# install deps\n",
        "!pip install --quiet alpaca_trade_api pandas numpy matplotlib pyppeteer schedule nest_asyncio\n",
        "\n",
        "import asyncio, nest_asyncio, time, schedule, os\n",
        "from pyppeteer import launch\n",
        "import pandas as pd, requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta, time as dtime\n",
        "import numpy as np\n",
        "from alpaca_trade_api.rest import REST, TimeFrame\n",
        "import datetime as dt\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Alpaca paper credentials\n",
        "API_KEY    = \"PKCD5EQESCEUAEK6P229\"                # â† your paper key\n",
        "API_SECRET = \"vMBP4zAug1Qyv8ngPNweTiI3GINrlQS5rtT8LFYC\"  # â† your paper secret\n",
        "BASE_URL   = \"https://paper-api.alpaca.markets\"     # â† paper endpoint\n",
        "\n",
        "api = REST(API_KEY, API_SECRET, BASE_URL, api_version=\"v2\")\n",
        "\n",
        "# Where to save the scraped CSV\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/quant/Everyday_Stocks\"\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "\n",
        "# How many to pick & weights\n",
        "PICK_COUNT = 10\n",
        "PCT_WEIGHT = 0.10   # 10% pctChange, 90% market cap\n",
        "MAX_USAGE  = 1    # use up to 70% of buying power each day\n",
        "\n",
        "# Market hours / schedule\n",
        "SCRAPE_TIME = \"09:55\"\n",
        "BUY_TIME    = \"10:00\"\n",
        "SELL_TIME   = \"14:00\"\n",
        "WIN_START   = \"09:30\"\n",
        "WIN_END     = \"16:00\"\n",
        "RATE_SLEEP  = 0  # throttle for Alpaca/minuteâ€bar pulls\n",
        "\n",
        "# â”€â”€â”€ SCRAPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "GAINERS_URL = \"https://stockanalysis.com/markets/gainers/\"\n",
        "\n",
        "async def _scrape_top50():\n",
        "    browser = await launch(headless=True,\n",
        "                          args=[\"--no-sandbox\",\"--disable-setuid-sandbox\"])\n",
        "    page = await browser.newPage()\n",
        "    await page.goto(GAINERS_URL, {\"waitUntil\":\"networkidle2\"})\n",
        "    await page.waitForSelector(\"table#main-table tbody tr\")\n",
        "\n",
        "    # click 20â†’50 rows\n",
        "    span20 = (await page.xpath(\"//span[normalize-space(text())='20 Rows']\"))[0]\n",
        "    btn20  = await page.evaluateHandle(\"(el)=>el.closest('button')\", span20)\n",
        "    await btn20.click(); await asyncio.sleep(0.3)\n",
        "    await page.click(\"button[title='Show 50 Rows']\"); await asyncio.sleep(0.3)\n",
        "\n",
        "    # wait for exactly 50 rows\n",
        "    await page.waitForFunction(\n",
        "      \"()=>document.querySelectorAll('table#main-table tbody tr').length===50\",\n",
        "      {\"timeout\":10000}\n",
        "    ); await asyncio.sleep(0.3)\n",
        "\n",
        "    # find col indices\n",
        "    cols = await page.evaluate(\"\"\"\n",
        "      () => Array.from(\n",
        "         document.querySelectorAll('table#main-table thead th')\n",
        "      ).map(th=>th.textContent.trim())\n",
        "    \"\"\")\n",
        "    i_sym = cols.index(\"Symbol\")\n",
        "    i_vol = cols.index(\"Volume\")\n",
        "    i_cap = cols.index(\"Market Cap\")\n",
        "    i_pct = next(i for i,h in enumerate(cols) if \"%\" in h and \"Change\" in h)\n",
        "\n",
        "    rows = await page.querySelectorAll(\"table#main-table tbody tr\")\n",
        "    data = []\n",
        "    for r in rows:\n",
        "        tds = await r.querySelectorAll(\"td\")\n",
        "        txt = [await page.evaluate(\"(el)=>el.textContent.trim()\",td) for td in tds]\n",
        "        def to_num(x):\n",
        "            x = x.replace(\",\",\"\").replace(\"M\",\"e6\").replace(\"K\",\"e3\")\n",
        "            try: return float(x)\n",
        "            except: return 0.0\n",
        "        data.append({\n",
        "            \"Symbol\":    txt[i_sym],\n",
        "            \"Volume\":    to_num(txt[i_vol]),\n",
        "            \"Market Cap\":to_num(txt[i_cap]),\n",
        "            \"PctChange\": float(txt[i_pct].replace(\"%\",\"\") or 0.0)\n",
        "        })\n",
        "    await browser.close()\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def scrape_top50():\n",
        "    TODAY = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    df = asyncio.get_event_loop().run_until_complete(_scrape_top50())\n",
        "\n",
        "    # fetch sector\n",
        "    secs = []\n",
        "    for s in df[\"Symbol\"]:\n",
        "        r = requests.get(f\"https://stockanalysis.com/stocks/{s.lower()}/\")\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        span = soup.find(\"span\",string=lambda t:t and t.strip()==\"Sector\")\n",
        "        a    = span.find_next_sibling(\"a\") if span else None\n",
        "        secs.append(a.get_text(strip=True) if a else \"\")\n",
        "        time.sleep(0.2)\n",
        "    df[\"Sector\"] = secs\n",
        "\n",
        "    fn = os.path.join(DRIVE_PATH, f\"top_{TODAY}_50.csv\")\n",
        "    df.to_csv(fn, index=False)\n",
        "    print(f\"â˜‘ï¸  Scraped â†’ {fn}\")\n",
        "\n",
        "# â”€â”€â”€ SELECTION + ORDER LOGIC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def pick_and_buy():\n",
        "    TODAY = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    fn = os.path.join(DRIVE_PATH, f\"top_{TODAY}_50.csv\")\n",
        "    if not os.path.exists(fn):\n",
        "        print(\"âš ï¸  no CSV yet, skipping buy\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(fn)\n",
        "    # normalize\n",
        "    df[\"Pct_norm\"] = (df[\"PctChange\"] - df[\"PctChange\"].min()) / (df[\"PctChange\"].ptp()+1e-9)\n",
        "    df[\"Cap_norm\"] = (df[\"Market Cap\"] - df[\"Market Cap\"].min()) / (df[\"Market Cap\"].ptp()+1e-9)\n",
        "    df[\"Score\"]    = PCT_WEIGHT*df[\"Pct_norm\"] + (1-PCT_WEIGHT)*df[\"Cap_norm\"]\n",
        "\n",
        "    picks = df.nlargest(PICK_COUNT,\"Score\")[\"Symbol\"].tolist()\n",
        "    print(\"ğŸ‘‰  BUY today:\", picks)\n",
        "\n",
        "    # fetch account buying power\n",
        "    account = api.get_account()\n",
        "    buying_power = float(account.cash) + float(account.buying_power)  # use cash+margin\n",
        "    budget = buying_power * MAX_USAGE\n",
        "    per_symbol = budget / PICK_COUNT\n",
        "\n",
        "    for s in picks:\n",
        "        # market order for $per_symbol notional\n",
        "        try:\n",
        "            api.submit_order(\n",
        "                symbol=s,\n",
        "                notional=round(per_symbol,2),\n",
        "                side=\"buy\",\n",
        "                type=\"market\",\n",
        "                time_in_force=\"day\"\n",
        "            )\n",
        "            print(\"  âœï¸  Bought\", s)\n",
        "        except Exception as e:\n",
        "            print(\"  âš ï¸ buy failed\", s, e)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "def sell_all():\n",
        "    positions = api.list_positions()\n",
        "    print(\"ğŸ‘‰  SELL all positions:\", [p.symbol for p in positions])\n",
        "    for p in positions:\n",
        "        try:\n",
        "            api.submit_order(\n",
        "                symbol=p.symbol,\n",
        "                qty=abs(int(float(p.qty))),\n",
        "                side=\"sell\",\n",
        "                type=\"market\",\n",
        "                time_in_force=\"day\"\n",
        "            )\n",
        "            print(\"  ğŸ—‘ï¸  Sold\", p.symbol)\n",
        "        except Exception as e:\n",
        "            print(\"  âš ï¸ sell failed\", p.symbol, e)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "# â”€â”€â”€ SCHEDULE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "schedule.every().day.at(SCRAPE_TIME).do(scrape_top50)\n",
        "schedule.every().day.at(BUY_TIME   ).do(pick_and_buy)\n",
        "schedule.every().day.at(SELL_TIME  ).do(sell_all)\n",
        "\n",
        "print(\"ğŸ•’  Scheduler started â€” Ctrl+C to stop\")\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRwZETlBL_F0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}